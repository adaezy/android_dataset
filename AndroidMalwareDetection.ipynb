{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "AndroidMalwareDetection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mFpB3DJ4oFv"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, transform\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.metrics import classification_report\n",
        "%matplotlib inline\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XNdRka34oFz"
      },
      "source": [
        "Custom Datset - Done \n",
        "\n",
        "create two two-layer fully-connected neural networks. The networks have an input dimension\n",
        "of N (given by the number of features in an app),\n",
        "a  hidden layer dimension of H (your choice), and perform classification over 2 classes.\n",
        "\n",
        "The first network uses a linear activation after the first fully connected layer,\n",
        "and the sigmoid function to compute the output. In other words, the first network\n",
        "has the following architecture (where FC means “fully connected layer”): input - FC - linear - FC - sigmoid. (done)\n",
        "\n",
        "The second network uses the ReLU activation function after the first layer, and the sigmoid to compute the output. Thus, the architecture of the second network is: input - FC - ReLU - FC - sigmoid. (done)\n",
        "\n",
        "The binary cross-entropy (i.e., BCELoss) is used to compute the loss in both cases. Use a subset of the training data as validation to perform hyperparamter tuning.\n",
        "(done)    \n",
        "\n",
        "\n",
        "Log your models’ training and use TensorBoard to plot learning curves that show the variation of \n",
        "the loss/accuracy with the number of epochs (fixed) for both training and validations sets, \n",
        "for two different values of H, for both networks. The learning rate can also be fixed,\n",
        "unless you’d like to experiment with two parameters (i.e., H and learning rate) at the same time.(done)\n",
        "\n",
        "Identify your best model according to the validation data, and use it to evaluate the performance \n",
        "on the test dataset in terms of accuracy. \n",
        "\n",
        "In addition, report the precision, recall \n",
        "and F-measure on the malware class. \n",
        "\n",
        "Between the linear and non-linear networks, which one has better performance?\n",
        "\n",
        "(Optional) Compare the model training times on CPU versus GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbasvaX44oFz"
      },
      "source": [
        "#Imported my data from Google Drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJkFgQsRZpiB"
      },
      "source": [
        "def load_data(file):\n",
        "    return pd.read_csv(file)\n",
        "androidtrain = load_data(\"/content/sample_data/AndroidAppsTrain.csv\")\n",
        "androidtest = load_data(\"/content/sample_data/AndroidAppsTest.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzjrVmoGn6BC"
      },
      "source": [
        "def split_data(dataset):\n",
        "    X_data,y_data = dataset.iloc[:,:-1],dataset.iloc[:,-1]\n",
        "    y_data = y_data.to_frame()  \n",
        "    return train_test_split(X_data,y_data,train_size = 0.7,random_state = 42,shuffle=True)\n",
        "X_train_set,X_val_set,y_train_set,y_val_set =  split_data(androidtrain)\n",
        "\n",
        "def split_test(dataset):\n",
        "  X_data,y_data = dataset.iloc[:,:-1],dataset.iloc[:,-1]\n",
        "  y_data = y_data.to_frame() \n",
        "  return  X_data,y_data\n",
        "X_test,y_test = split_test(androidtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCgWCLctRsfM",
        "outputId": "6ed7a9f2-6932-4324-d4ab-a4ca57751d00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(X_train_set.shape)\n",
        "print(y_train_set.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(103179, 471)\n",
            "(103179, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvZFuUgN4oF2"
      },
      "source": [
        "#Custom PyTorch Dataset\n",
        "class CustomDataSet(Dataset):\n",
        "    def __init__(self,features,target,transform = None):\n",
        "        self.X = features\n",
        "        self.y = target\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self,idx):      \n",
        "        data_features = torch.Tensor(self.X.values)\n",
        "        data_target = torch.Tensor(self.y.values)\n",
        "        return data_features,data_target\n",
        "            \n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8U8ieOH-U8Rt"
      },
      "source": [
        "X_train_set = torch.from_numpy(X_train_set.to_numpy()).float()\n",
        "y_train_set = torch.from_numpy(y_train_set.to_numpy()).float()\n",
        "X_val_set = torch.from_numpy(X_val_set.to_numpy()).float()\n",
        "y_val_set =torch.from_numpy(y_val_set.to_numpy()).float()\n",
        "\n",
        "X_test = torch.from_numpy(X_test.to_numpy()).float()\n",
        "y_test =torch.from_numpy(y_test.to_numpy()).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJgfNGGk4oF5"
      },
      "source": [
        "#androidtrain_data = CustomDataSet(X_train_set,y_train_set)\n",
        "###androidval_data = CustomDataSet(X_val_set,y_val_set)\n",
        "#androidtest_data = CustomDataSet(X_test,y_test)\n",
        "\n",
        "\n",
        "androidtrain_data = TensorDataset(X_train_set,y_train_set)\n",
        "androidval_data = TensorDataset(X_val_set,y_val_set)\n",
        "androidtest_data = TensorDataset(X_test,y_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SkTBIc94oF8",
        "outputId": "379fe27c-c9b2-4754-9160-408d66575b86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "batch_size = 128\n",
        "# split to train val\n",
        "dataset_size = len(androidtrain_data)\n",
        "print(dataset_size)\n",
        "print(len(androidtest_data))\n",
        "print(len(androidval_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "103179\n",
            "72599\n",
            "44220\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTpHDdAl4oF_"
      },
      "source": [
        "#Load into DataLoader\n",
        "train_dataloader = DataLoader(androidtrain_data, batch_size=batch_size)\n",
        "val_dataloader = DataLoader(androidval_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(androidtest_data, batch_size=batch_size,shuffle=True,num_workers = 2)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv4CmIQU4oGB",
        "outputId": "e13b5ad9-67d4-4bd2-973c-55679a1798cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(val_dataloader.batch_size)\n",
        "print(train_dataloader.sampler)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128\n",
            "<torch.utils.data.sampler.SequentialSampler object at 0x7f87183e9518>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8pC-5RJ4oGE"
      },
      "source": [
        "#len(train_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQeeMzbH4oGH"
      },
      "source": [
        "#dataiter = iter(train_dataloader)\n",
        "#myfeatures, labels = dataiter.next()\n",
        "#print(myfeatures.shape)\n",
        "#print(labels.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg4hftfg4oGK"
      },
      "source": [
        "#Define First model with Linear and sigmoid output layer\n",
        "class Net(nn.Module):\n",
        "    def __init__(self,input_size,output_size):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size,5) # Change hidden layer  =[5,10]\n",
        "        self.fc2 = nn.Linear(5,output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        output = self.sigmoid(x)\n",
        "        return output\n",
        "\n",
        "output_dim = 1\n",
        "input_dim = 471\n",
        "net = Net(input_dim,output_dim)\n",
        "if torch.cuda.is_available():\n",
        "    net.cuda()\n",
        "learning_rate = 0.01\n",
        "optimizer1 = optim.SGD(net.parameters(), lr = learning_rate)\n",
        "criterion1 = nn.BCELoss() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fgy5Nbjj4oGM"
      },
      "source": [
        "#Define Second Model with ReLu and sigmoid output layer \n",
        "class Net2(nn.Module):\n",
        "    def __init__(self,input_size,output_size):\n",
        "        super(Net2, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size,5) # Change hidden layer  =[5,10]\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(5,output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        relu = self.relu(x)\n",
        "        output = self.fc2(relu)\n",
        "        output = self.sigmoid(output)\n",
        "        return output\n",
        "\n",
        "output_dim = 1\n",
        "input_dim = 471\n",
        "net2 = Net2(input_dim,output_dim)\n",
        "if torch.cuda.is_available():\n",
        "    net2.cuda()\n",
        "learning_rate2 = 0.01\n",
        "optimizer2 = optim.SGD(net2.parameters(), lr=learning_rate2)\n",
        "criterion2 = nn.BCELoss()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3s8cIlEvte6"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cgqb035wu_01",
        "outputId": "5f272134-25fe-4f8f-f315-d7df488017bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "#Train model with net()....Linear Model\n",
        "writer = SummaryWriter('runs/linear_5/')\n",
        "epochs = 50\n",
        "train_losses, val_losses = [], [] \n",
        "train_accuracy = []\n",
        "val_accuracy =[]\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    total_train = 0\n",
        "    correct_train = 0\n",
        "    val_loss = 0\n",
        "    total_val = 0\n",
        "    correct_val = 0\n",
        "    \n",
        "    \n",
        "    for X,y in train_dataloader:\n",
        "         if torch.cuda.is_available():\n",
        "          optimizer1.zero_grad()\n",
        "          \n",
        "          X_1 = X.cuda()\n",
        "          y_1 = y.cuda()\n",
        "          pred = net(X_1)\n",
        "          #print(\"X:\",X_1.shape)\n",
        "          #print(\"y:\",y_1.shape)\n",
        "          #print(\"Pred:\",pred.shape) \n",
        "          loss = criterion1(pred, y_1)\n",
        "          \n",
        "          loss.backward()\n",
        "          optimizer1.step()        \n",
        "          running_loss += loss.item()\n",
        "        \n",
        "          #accuracy\n",
        "          predicted = pred.data > 0.5\n",
        "          correct_train += (predicted==y_1.view_as(predicted)).sum().item()\n",
        "          total_train += int(y_1.shape[0])\n",
        "          #print(\"GPU train\")\n",
        "         else:\n",
        "          optimizer1.zero_grad()\n",
        "          pred = net(X)\n",
        "          #print(\"X:\",X.shape)\n",
        "          #print(\"y:\",y.shape)\n",
        "          #print(\"Pred:\",pred.shape)     \n",
        "          loss = criterion1(pred, y)\n",
        "          \n",
        "          loss.backward()\n",
        "          optimizer1.step()        \n",
        "          running_loss += loss.item()\n",
        "\n",
        "          #accuracy\n",
        "          predicted = pred.data > 0.5\n",
        "          correct_train += (predicted==y.view_as(predicted)).sum().item()\n",
        "          total_train += int(y.shape[0])\n",
        "          #print(\"CPU train\")\n",
        " \n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for X,y in val_dataloader:\n",
        "        if torch.cuda.is_available():\n",
        "          X_1 = X.cuda()\n",
        "          y_1 = y.cuda()\n",
        "          pred = net(X_1)\n",
        "          val_loss += criterion1(pred, y_1)\n",
        "          \n",
        "          #accuracy\n",
        "          predicted_t = pred.data > 0.5\n",
        "          correct_val += (predicted_t==y_1.view_as(predicted_t)).sum().item()\n",
        "          total_val += int(y_1.shape[0])\n",
        "          #print(\"GPU_val train\")\n",
        "      \n",
        "        else:\n",
        "          pred = net(X)\n",
        "          #print(\"X:\",X.shape)\n",
        "          #print(\"y:\",y.shape)\n",
        "          #print(\"Pred:\",pred.shape)           \n",
        "          val_loss += criterion1(pred, y)\n",
        "          \n",
        "          #accuracy\n",
        "          predicted_t = pred.data > 0.5\n",
        "          correct_val += (predicted_t==y.view_as(predicted_t)).sum().item()\n",
        "          total_val += int(y.shape[0])\n",
        "          #print(\"CPU_val train\")\n",
        "                          \n",
        "    writer.add_scalar(\"Train Loss/Epoch\", running_loss/len(train_dataloader), e+1)\n",
        "    writer.add_scalar(\"Train Accuracy/Epoch\", ( 100*correct_train / total_train), e+1)\n",
        "    writer.add_scalar(\"Validation Loss/Epoch\", (val_loss/len(val_dataloader)), e+1)\n",
        "    writer.add_scalar(\"Validation Accuracy/Epoch\", (100* correct_val / total_val), e+1)\n",
        "    train_losses.append(running_loss/len(train_dataloader))\n",
        "    val_losses.append(val_loss/len(val_dataloader))\n",
        "    train_accuracy.append(100 * correct_train // total_train)\n",
        "    val_accuracy.append(100 * correct_val // total_val)\n",
        "    print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "          \"Training Loss: {:.3f}.. \".format(running_loss/len(train_dataloader)),\n",
        "          \"Training Accuracy:%d %%\"%( 100*correct_train / total_train),\n",
        "          \"Val Loss: {:.3f}.. \".format((val_loss/len(val_dataloader))),\n",
        "          \"val Accuracy: :%d %%\"%(100* correct_val / total_val))\n",
        "    \n",
        "writer.flush()\n",
        "    \n",
        "print('Finished Training')\n",
        "\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/50..  Training Loss: 0.328..  Training Accuracy:90 % Val Loss: 0.235..  val Accuracy: :92 %\n",
            "Epoch: 2/50..  Training Loss: 0.201..  Training Accuracy:93 % Val Loss: 0.175..  val Accuracy: :94 %\n",
            "Epoch: 3/50..  Training Loss: 0.166..  Training Accuracy:94 % Val Loss: 0.155..  val Accuracy: :94 %\n",
            "Epoch: 4/50..  Training Loss: 0.151..  Training Accuracy:95 % Val Loss: 0.145..  val Accuracy: :95 %\n",
            "Epoch: 5/50..  Training Loss: 0.143..  Training Accuracy:95 % Val Loss: 0.139..  val Accuracy: :95 %\n",
            "Epoch: 6/50..  Training Loss: 0.138..  Training Accuracy:95 % Val Loss: 0.135..  val Accuracy: :95 %\n",
            "Epoch: 7/50..  Training Loss: 0.135..  Training Accuracy:95 % Val Loss: 0.133..  val Accuracy: :95 %\n",
            "Epoch: 8/50..  Training Loss: 0.132..  Training Accuracy:95 % Val Loss: 0.131..  val Accuracy: :95 %\n",
            "Epoch: 9/50..  Training Loss: 0.131..  Training Accuracy:95 % Val Loss: 0.129..  val Accuracy: :95 %\n",
            "Epoch: 10/50..  Training Loss: 0.129..  Training Accuracy:95 % Val Loss: 0.128..  val Accuracy: :95 %\n",
            "Epoch: 11/50..  Training Loss: 0.128..  Training Accuracy:95 % Val Loss: 0.127..  val Accuracy: :95 %\n",
            "Epoch: 12/50..  Training Loss: 0.127..  Training Accuracy:95 % Val Loss: 0.126..  val Accuracy: :95 %\n",
            "Epoch: 13/50..  Training Loss: 0.126..  Training Accuracy:95 % Val Loss: 0.125..  val Accuracy: :95 %\n",
            "Epoch: 14/50..  Training Loss: 0.125..  Training Accuracy:95 % Val Loss: 0.125..  val Accuracy: :95 %\n",
            "Epoch: 15/50..  Training Loss: 0.124..  Training Accuracy:95 % Val Loss: 0.124..  val Accuracy: :95 %\n",
            "Epoch: 16/50..  Training Loss: 0.124..  Training Accuracy:95 % Val Loss: 0.124..  val Accuracy: :95 %\n",
            "Epoch: 17/50..  Training Loss: 0.123..  Training Accuracy:95 % Val Loss: 0.123..  val Accuracy: :96 %\n",
            "Epoch: 18/50..  Training Loss: 0.123..  Training Accuracy:95 % Val Loss: 0.123..  val Accuracy: :96 %\n",
            "Epoch: 19/50..  Training Loss: 0.122..  Training Accuracy:96 % Val Loss: 0.122..  val Accuracy: :96 %\n",
            "Epoch: 20/50..  Training Loss: 0.122..  Training Accuracy:96 % Val Loss: 0.122..  val Accuracy: :96 %\n",
            "Epoch: 21/50..  Training Loss: 0.121..  Training Accuracy:96 % Val Loss: 0.122..  val Accuracy: :96 %\n",
            "Epoch: 22/50..  Training Loss: 0.121..  Training Accuracy:96 % Val Loss: 0.122..  val Accuracy: :96 %\n",
            "Epoch: 23/50..  Training Loss: 0.121..  Training Accuracy:96 % Val Loss: 0.121..  val Accuracy: :96 %\n",
            "Epoch: 24/50..  Training Loss: 0.121..  Training Accuracy:96 % Val Loss: 0.121..  val Accuracy: :96 %\n",
            "Epoch: 25/50..  Training Loss: 0.120..  Training Accuracy:96 % Val Loss: 0.121..  val Accuracy: :96 %\n",
            "Epoch: 26/50..  Training Loss: 0.120..  Training Accuracy:96 % Val Loss: 0.121..  val Accuracy: :96 %\n",
            "Epoch: 27/50..  Training Loss: 0.120..  Training Accuracy:96 % Val Loss: 0.121..  val Accuracy: :96 %\n",
            "Epoch: 28/50..  Training Loss: 0.120..  Training Accuracy:96 % Val Loss: 0.120..  val Accuracy: :96 %\n",
            "Epoch: 29/50..  Training Loss: 0.119..  Training Accuracy:96 % Val Loss: 0.120..  val Accuracy: :96 %\n",
            "Epoch: 30/50..  Training Loss: 0.119..  Training Accuracy:96 % Val Loss: 0.120..  val Accuracy: :96 %\n",
            "Epoch: 31/50..  Training Loss: 0.119..  Training Accuracy:96 % Val Loss: 0.120..  val Accuracy: :96 %\n",
            "Epoch: 32/50..  Training Loss: 0.119..  Training Accuracy:96 % Val Loss: 0.120..  val Accuracy: :96 %\n",
            "Epoch: 33/50..  Training Loss: 0.119..  Training Accuracy:96 % Val Loss: 0.120..  val Accuracy: :96 %\n",
            "Epoch: 34/50..  Training Loss: 0.119..  Training Accuracy:96 % Val Loss: 0.120..  val Accuracy: :96 %\n",
            "Epoch: 35/50..  Training Loss: 0.118..  Training Accuracy:96 % Val Loss: 0.120..  val Accuracy: :96 %\n",
            "Epoch: 36/50..  Training Loss: 0.118..  Training Accuracy:96 % Val Loss: 0.119..  val Accuracy: :96 %\n",
            "Epoch: 37/50..  Training Loss: 0.118..  Training Accuracy:96 % Val Loss: 0.119..  val Accuracy: :96 %\n",
            "Epoch: 38/50..  Training Loss: 0.118..  Training Accuracy:96 % Val Loss: 0.119..  val Accuracy: :96 %\n",
            "Epoch: 39/50..  Training Loss: 0.118..  Training Accuracy:96 % Val Loss: 0.119..  val Accuracy: :96 %\n",
            "Epoch: 40/50..  Training Loss: 0.118..  Training Accuracy:96 % Val Loss: 0.119..  val Accuracy: :96 %\n",
            "Epoch: 41/50..  Training Loss: 0.118..  Training Accuracy:96 % Val Loss: 0.119..  val Accuracy: :96 %\n",
            "Epoch: 42/50..  Training Loss: 0.118..  Training Accuracy:96 % Val Loss: 0.119..  val Accuracy: :96 %\n",
            "Epoch: 43/50..  Training Loss: 0.118..  Training Accuracy:96 % Val Loss: 0.119..  val Accuracy: :96 %\n",
            "Epoch: 44/50..  Training Loss: 0.118..  Training Accuracy:96 % Val Loss: 0.119..  val Accuracy: :96 %\n",
            "Epoch: 45/50..  Training Loss: 0.117..  Training Accuracy:96 % Val Loss: 0.119..  val Accuracy: :96 %\n",
            "Epoch: 46/50..  Training Loss: 0.117..  Training Accuracy:96 % Val Loss: 0.119..  val Accuracy: :96 %\n",
            "Epoch: 47/50..  Training Loss: 0.117..  Training Accuracy:96 % Val Loss: 0.119..  val Accuracy: :96 %\n",
            "Epoch: 48/50..  Training Loss: 0.117..  Training Accuracy:96 % Val Loss: 0.119..  val Accuracy: :96 %\n",
            "Epoch: 49/50..  Training Loss: 0.117..  Training Accuracy:96 % Val Loss: 0.119..  val Accuracy: :96 %\n",
            "Epoch: 50/50..  Training Loss: 0.117..  Training Accuracy:96 % Val Loss: 0.119..  val Accuracy: :96 %\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A08yW5CAtsEG"
      },
      "source": [
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxSjhcYOqGNT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIwNZnmKawqV",
        "outputId": "4f208012-72cf-4755-ae01-3803dfba8d25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "#Train model with net()....Non-Linear Model\n",
        "writer = SummaryWriter('runs/nonlinear_5/') \n",
        "epochs = 50\n",
        "train_losses2, val_losses2 = [], [] \n",
        "train_accuracy2 = []\n",
        "val_accuracy2 =[]\n",
        "for e in range(epochs):\n",
        "    running_loss2 = 0\n",
        "    total_train2 = 0\n",
        "    correct_train2 = 0\n",
        "    val_loss2 = 0\n",
        "    total_val2 = 0\n",
        "    correct_val2 = 0\n",
        "    \n",
        "    \n",
        "    for X_new,y_new in train_dataloader:\n",
        "         if torch.cuda.is_available():\n",
        "          optimizer2.zero_grad()\n",
        "          X_2 = X_new.cuda()\n",
        "          y_2 = y_new.cuda()\n",
        "          pred2 = net2(X_2)\n",
        "          #print(\"X:\",X_1.shape)\n",
        "          #print(\"y:\",y_1.shape)\n",
        "          #print(\"Pred:\",pred.shape) \n",
        "          loss2 = criterion2(pred2, y_2)\n",
        "          loss2.backward()\n",
        "          optimizer2.step()        \n",
        "          running_loss2 += loss2.item()\n",
        "        \n",
        "          #accuracy\n",
        "          predicted2 = pred2.data > 0.5\n",
        "          #top_p,predicted2 = pred2.topk(1,dim=1)\n",
        "          correct_train2 += (predicted2==y_2.view_as(predicted2)).sum().item()\n",
        "          total_train2 += int(y_2.shape[0])\n",
        "          #print(\"GPU train\")\n",
        "         else:\n",
        "          optimizer2.zero_grad()\n",
        "          pred2 = net2(X_new)\n",
        "          #print(\"X:\",X.shape)\n",
        "          #print(\"y:\",y.shape)\n",
        "          #print(\"Pred:\",pred.shape)     \n",
        "          loss2 = criterion2(pred2, y_new)\n",
        "          loss2.backward()\n",
        "          optimizer2.step()        \n",
        "          running_loss2 += loss2.item()\n",
        "\n",
        "          #accuracy\n",
        "          predicted2 = pred2.data > 0.5\n",
        "          #top_p,predicted2 = pred2.topk(1,dim=1)\n",
        "          correct_train2 += (predicted2==y_new.view_as(predicted2)).sum().item()\n",
        "          total_train2 += int(y_new.shape[0])\n",
        "          #print(\"CPU train\")\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for X_new,y_new in val_dataloader:\n",
        "        if torch.cuda.is_available():\n",
        "          X_2 = X_new.cuda()\n",
        "          y_2 = y_new.cuda()\n",
        "          pred2 = net2(X_2)\n",
        "          \n",
        "          val_loss2 += criterion2(pred2, y_2)\n",
        "          \n",
        "          #accuracy\n",
        "          predicted_t2 = pred2.data > 0.5\n",
        "          #top_p,predicted_t2 = pred2.topk(1,dim=1)\n",
        "          correct_val2 += (predicted_t2==y_2.view_as(predicted_t2)).sum().item()\n",
        "          total_val2 += int(y_2.shape[0])\n",
        "          #print(\"GPU_val train\")\n",
        "        \n",
        "      \n",
        "        else:\n",
        "          pred2 = net2(X_new)\n",
        "          #print(\"X:\",X.shape)\n",
        "          #print(\"y:\",y.shape)\n",
        "          #print(\"Pred:\",pred.shape)           \n",
        "          val_loss2 += criterion2(pred, y_new)\n",
        "          #accuracy\n",
        "          #top_p,predicted2_t = pred2.topk(1,dim=1)\n",
        "          predicted2_t = pred2.data > 0.5\n",
        "          correct_val2 += (predicted_t2==y_new.view_as(predicted_t2)).sum().item()\n",
        "          total_val2 += int(y_new.shape[0])\n",
        "          #print(\"CPU_val train\")\n",
        "\n",
        "    \n",
        "    writer.add_scalar(\"Train Loss/Epoch\", running_loss2/len(train_dataloader), e+1)\n",
        "    writer.add_scalar(\"Train Accuracy/Epoch\", ( 100*correct_train2 / total_train2), e+1)\n",
        "    writer.add_scalar(\"Validation Loss/Epoch\", (val_loss2/len(val_dataloader)), e+1)\n",
        "    writer.add_scalar(\"Validation Accuracy/Epoch\", (100* correct_val2 / total_val2), e+1)\n",
        "    print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "          \"Training Loss: {:.3f}.. \".format(running_loss2/len(train_dataloader)),\n",
        "          \"Training Accuracy:%d %%\"%( 100*correct_train2 / total_train2),\n",
        "          \"Val Loss: {:.3f}.. \".format((val_loss2/len(val_dataloader))),\n",
        "          \"val Accuracy: :%d %%\"%(100* correct_val2 / total_val2))\n",
        "    \n",
        "writer.flush()\n",
        "    \n",
        "print('Finished Validating')\n",
        "\n",
        "writer.close()\n",
        "     "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/50..  Training Loss: 0.374..  Training Accuracy:90 % Val Loss: 0.288..  val Accuracy: :90 %\n",
            "Epoch: 2/50..  Training Loss: 0.264..  Training Accuracy:90 % Val Loss: 0.238..  val Accuracy: :90 %\n",
            "Epoch: 3/50..  Training Loss: 0.221..  Training Accuracy:90 % Val Loss: 0.192..  val Accuracy: :92 %\n",
            "Epoch: 4/50..  Training Loss: 0.177..  Training Accuracy:93 % Val Loss: 0.161..  val Accuracy: :94 %\n",
            "Epoch: 5/50..  Training Loss: 0.155..  Training Accuracy:94 % Val Loss: 0.147..  val Accuracy: :95 %\n",
            "Epoch: 6/50..  Training Loss: 0.145..  Training Accuracy:95 % Val Loss: 0.140..  val Accuracy: :95 %\n",
            "Epoch: 7/50..  Training Loss: 0.139..  Training Accuracy:95 % Val Loss: 0.136..  val Accuracy: :95 %\n",
            "Epoch: 8/50..  Training Loss: 0.136..  Training Accuracy:95 % Val Loss: 0.133..  val Accuracy: :95 %\n",
            "Epoch: 9/50..  Training Loss: 0.133..  Training Accuracy:95 % Val Loss: 0.131..  val Accuracy: :95 %\n",
            "Epoch: 10/50..  Training Loss: 0.131..  Training Accuracy:95 % Val Loss: 0.129..  val Accuracy: :95 %\n",
            "Epoch: 11/50..  Training Loss: 0.129..  Training Accuracy:95 % Val Loss: 0.128..  val Accuracy: :95 %\n",
            "Epoch: 12/50..  Training Loss: 0.128..  Training Accuracy:95 % Val Loss: 0.127..  val Accuracy: :95 %\n",
            "Epoch: 13/50..  Training Loss: 0.127..  Training Accuracy:95 % Val Loss: 0.126..  val Accuracy: :95 %\n",
            "Epoch: 14/50..  Training Loss: 0.126..  Training Accuracy:95 % Val Loss: 0.125..  val Accuracy: :95 %\n",
            "Epoch: 15/50..  Training Loss: 0.125..  Training Accuracy:95 % Val Loss: 0.124..  val Accuracy: :95 %\n",
            "Epoch: 16/50..  Training Loss: 0.124..  Training Accuracy:95 % Val Loss: 0.124..  val Accuracy: :96 %\n",
            "Epoch: 17/50..  Training Loss: 0.123..  Training Accuracy:95 % Val Loss: 0.123..  val Accuracy: :96 %\n",
            "Epoch: 18/50..  Training Loss: 0.123..  Training Accuracy:95 % Val Loss: 0.123..  val Accuracy: :96 %\n",
            "Epoch: 19/50..  Training Loss: 0.122..  Training Accuracy:95 % Val Loss: 0.122..  val Accuracy: :96 %\n",
            "Epoch: 20/50..  Training Loss: 0.122..  Training Accuracy:95 % Val Loss: 0.122..  val Accuracy: :96 %\n",
            "Epoch: 21/50..  Training Loss: 0.121..  Training Accuracy:96 % Val Loss: 0.121..  val Accuracy: :96 %\n",
            "Epoch: 22/50..  Training Loss: 0.121..  Training Accuracy:96 % Val Loss: 0.121..  val Accuracy: :96 %\n",
            "Epoch: 23/50..  Training Loss: 0.120..  Training Accuracy:96 % Val Loss: 0.121..  val Accuracy: :96 %\n",
            "Epoch: 24/50..  Training Loss: 0.120..  Training Accuracy:96 % Val Loss: 0.120..  val Accuracy: :96 %\n",
            "Epoch: 25/50..  Training Loss: 0.120..  Training Accuracy:96 % Val Loss: 0.120..  val Accuracy: :96 %\n",
            "Epoch: 26/50..  Training Loss: 0.119..  Training Accuracy:96 % Val Loss: 0.120..  val Accuracy: :96 %\n",
            "Epoch: 27/50..  Training Loss: 0.119..  Training Accuracy:96 % Val Loss: 0.119..  val Accuracy: :96 %\n",
            "Epoch: 28/50..  Training Loss: 0.119..  Training Accuracy:96 % Val Loss: 0.119..  val Accuracy: :96 %\n",
            "Epoch: 29/50..  Training Loss: 0.118..  Training Accuracy:96 % Val Loss: 0.119..  val Accuracy: :96 %\n",
            "Epoch: 30/50..  Training Loss: 0.118..  Training Accuracy:96 % Val Loss: 0.119..  val Accuracy: :96 %\n",
            "Epoch: 31/50..  Training Loss: 0.118..  Training Accuracy:96 % Val Loss: 0.119..  val Accuracy: :96 %\n",
            "Epoch: 32/50..  Training Loss: 0.117..  Training Accuracy:96 % Val Loss: 0.118..  val Accuracy: :96 %\n",
            "Epoch: 33/50..  Training Loss: 0.117..  Training Accuracy:96 % Val Loss: 0.118..  val Accuracy: :96 %\n",
            "Epoch: 34/50..  Training Loss: 0.117..  Training Accuracy:96 % Val Loss: 0.118..  val Accuracy: :96 %\n",
            "Epoch: 35/50..  Training Loss: 0.117..  Training Accuracy:96 % Val Loss: 0.118..  val Accuracy: :96 %\n",
            "Epoch: 36/50..  Training Loss: 0.116..  Training Accuracy:96 % Val Loss: 0.117..  val Accuracy: :96 %\n",
            "Epoch: 37/50..  Training Loss: 0.116..  Training Accuracy:96 % Val Loss: 0.117..  val Accuracy: :96 %\n",
            "Epoch: 38/50..  Training Loss: 0.116..  Training Accuracy:96 % Val Loss: 0.117..  val Accuracy: :96 %\n",
            "Epoch: 39/50..  Training Loss: 0.116..  Training Accuracy:96 % Val Loss: 0.117..  val Accuracy: :96 %\n",
            "Epoch: 40/50..  Training Loss: 0.115..  Training Accuracy:96 % Val Loss: 0.117..  val Accuracy: :96 %\n",
            "Epoch: 41/50..  Training Loss: 0.115..  Training Accuracy:96 % Val Loss: 0.116..  val Accuracy: :96 %\n",
            "Epoch: 42/50..  Training Loss: 0.115..  Training Accuracy:96 % Val Loss: 0.116..  val Accuracy: :96 %\n",
            "Epoch: 43/50..  Training Loss: 0.115..  Training Accuracy:96 % Val Loss: 0.116..  val Accuracy: :96 %\n",
            "Epoch: 44/50..  Training Loss: 0.115..  Training Accuracy:96 % Val Loss: 0.116..  val Accuracy: :96 %\n",
            "Epoch: 45/50..  Training Loss: 0.114..  Training Accuracy:96 % Val Loss: 0.116..  val Accuracy: :96 %\n",
            "Epoch: 46/50..  Training Loss: 0.114..  Training Accuracy:96 % Val Loss: 0.116..  val Accuracy: :96 %\n",
            "Epoch: 47/50..  Training Loss: 0.114..  Training Accuracy:96 % Val Loss: 0.116..  val Accuracy: :96 %\n",
            "Epoch: 48/50..  Training Loss: 0.114..  Training Accuracy:96 % Val Loss: 0.115..  val Accuracy: :96 %\n",
            "Epoch: 49/50..  Training Loss: 0.114..  Training Accuracy:96 % Val Loss: 0.115..  val Accuracy: :96 %\n",
            "Epoch: 50/50..  Training Loss: 0.113..  Training Accuracy:96 % Val Loss: 0.115..  val Accuracy: :96 %\n",
            "Finished Validating\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSuO66LXlxM_"
      },
      "source": [
        "Answer: According to the validation data, my best model is the net2() nonlinear model since it converges faster than the linear model, hence, I am using it on my test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl8ykixx4oGU",
        "outputId": "e1e20473-9e34-42da-e3e4-35ac2bff5ede",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "#Test model on Test Dataset\n",
        "#Train model with net2()....Non-Linear Model with hidden layer \n",
        "writer = SummaryWriter('runs/test/') \n",
        "epochs = 50\n",
        "test_losses2 = [] \n",
        "test_accuracy2 =[]\n",
        "all_predicts =[]\n",
        "all_labels =[]\n",
        "for e in range(epochs):\n",
        "  test_loss2 = 0\n",
        "  total_test2 = 0\n",
        "  correct_test2 = 0\n",
        "    \n",
        "  with torch.no_grad():\n",
        "      for X_new,y_new in test_dataloader:\n",
        "        if torch.cuda.is_available():\n",
        "          X_2 = X_new.cuda()\n",
        "          y_2 = y_new.cuda()\n",
        "          pred2 = net2(X_2)\n",
        "          test_loss2 += criterion2(pred2, y_2)\n",
        "          #accuracy\n",
        "          predicted_t2 = pred2.data > 0.5\n",
        "          final_predicted = predicted_t2.int().cpu().data.numpy()\n",
        "          label = y_2.cpu()\n",
        "          label = torch.gt(label , 0).int().data.numpy()\n",
        "          correct_test2 += (predicted_t2==y_2.view_as(predicted_t2)).sum().item()\n",
        "          total_test2 += int(y_2.shape[0])\n",
        "          #print(\"GPU_val train\")\n",
        "      \n",
        "        else:\n",
        "          pred2 = net2(X_new)\n",
        "          #print(\"X:\",X.shape)\n",
        "          #print(\"y:\",y.shape)\n",
        "          #print(\"Pred:\",pred.shape)           \n",
        "          test_loss2 += criterion2(pred, y_new)\n",
        "          #accuracy\n",
        "          predicted2_t = pred2.data > 0.5\n",
        "          final_predicted = predicted_t2.data.numpy()\n",
        "          label = torch.gt(y_new , 0)\n",
        "          correct_test2 += (predicted_t2==y_new.view_as(predicted_t2)).sum().item()\n",
        "          total_test2 += int(y_new.shape[0])                \n",
        "  all_labels.append(label)\n",
        "  all_predicts.append(final_predicted)       \n",
        "  \n",
        "  writer.add_scalar(\"Validation Loss/Epoch\", (test_loss2/len(test_dataloader)), e+1)\n",
        "  writer.add_scalar(\"Validation Accuracy/Epoch\", (100* correct_test2 / total_test2), e+1)\n",
        "  print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
        "          \"Test Loss: {:.3f}.. \".format((test_loss2/len(test_dataloader))),\n",
        "          \"Test Accuracy: :%d %%\"%(100* correct_test2 / total_test2))\n",
        "writer.flush()\n",
        "    \n",
        "print('Finished Testing')\n",
        "\n",
        "writer.close()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 2/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 3/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 4/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 5/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 6/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 7/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 8/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 9/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 10/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 11/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 12/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 13/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 14/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 15/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 16/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 17/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 18/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 19/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 20/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 21/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 22/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 23/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 24/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 25/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 26/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 27/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 28/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 29/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 30/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 31/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 32/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 33/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 34/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 35/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 36/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 37/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 38/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 39/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 40/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 41/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 42/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 43/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 44/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 45/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 46/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 47/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 48/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 49/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Epoch: 50/50..  Test Loss: 0.115..  Test Accuracy: :96 %\n",
            "Finished Testing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_nIZGy74oGa",
        "outputId": "4066b175-7a62-4fd9-9dd0-388379501fe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# Evaluate Precision, Recall and F-measure\n",
        "y_true = all_labels\n",
        "y_pred = all_predicts\n",
        "def flatten(x):\n",
        "    result = []\n",
        "    for el in x:\n",
        "        if hasattr(el, \"__iter__\") and not isinstance(el, str):\n",
        "            result.extend(flatten(el))\n",
        "        else:\n",
        "            result.append(el)\n",
        "    return result\n",
        "y_true = flatten(y_true)\n",
        "y_pred = flatten(y_pred)\n",
        "target_names = ['class 0', 'class 1']\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.98      0.99      0.98      1055\n",
            "     class 1       0.92      0.73      0.81        95\n",
            "\n",
            "    accuracy                           0.97      1150\n",
            "   macro avg       0.95      0.86      0.90      1150\n",
            "weighted avg       0.97      0.97      0.97      1150\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz1BDRlEwLvK"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvsj7EeA2FX7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJkswRQd8MQF"
      },
      "source": [
        "Answers:\n",
        "\n",
        "For my experiments, I used two different hidden layers[5,10] to test my two models. After running with different learning rates, I noticed I got a better performace with my non linear model(net2()) since it converges the fastest with hidden model = 10. \n",
        "\n",
        "Answer:\n",
        "\n",
        "For my test model, I got an accuracy of 96% same with both my linear and non-linear model.\n",
        "\n",
        "Answer:\n",
        "\n",
        "The non-linear model is slightly better since it converges faster, however both converges at 96% accuracy."
      ]
    }
  ]
}